from __future__ import annotations
# src/main_window/main_widget/sequence_card_tab/components/display/disk_cache_manager.py
import hashlib
import json
import logging
import os
import time
from pathlib import Path
from typing import Any,Optional

from PyQt6.QtCore import QSize
from PyQt6.QtGui import QPixmap


class DiskCacheManager:
    """
    Manages disk-based caching of processed images for ultra-fast loading.

    Features:
    - Persistent cache across application sessions
    - Automatic cache invalidation based on source file modification
    - Size-based cache cleanup to prevent disk bloat
    - Metadata tracking for cache management
    - Safe fallback if cache operations fail
    """

    def __init__(self, cache_dir: str = None, max_cache_size_mb: int = 1000):
        """
        Initialize the disk cache manager.

        Args:
            cache_dir: Directory for cache files. If None, uses default location.
            max_cache_size_mb: Maximum cache size in MB before cleanup
        """
        self.max_cache_size_mb = max_cache_size_mb
        self.cache_enabled = True

        # Set up cache directory
        if cache_dir is None:
            from utils.path_helpers import get_user_editable_resource_path

            try:
                cache_dir = os.path.join(
                    get_user_editable_resource_path(""), "image_cache"
                )
            except:
                # Fallback to temp directory
                import tempfile

                cache_dir = os.path.join(
                    tempfile.gettempdir(), "kinetic_constructor_cache"
                )

        self.cache_dir = Path(cache_dir)
        self.metadata_file = self.cache_dir / "cache_metadata.json"

        # Initialize cache directory and metadata
        self._initialize_cache()

        # Cache statistics
        self.cache_hits = 0
        self.cache_misses = 0
        self.cache_writes = 0
        self.cache_cleanups = 0

    def _initialize_cache(self) -> None:
        """Initialize cache directory and load metadata."""
        try:
            # Create cache directory if it doesn't exist
            self.cache_dir.mkdir(parents=True, exist_ok=True)

            # Load or create metadata
            if self.metadata_file.exists():
                try:
                    with open(self.metadata_file) as f:
                        self.metadata = json.load(f)
                except (OSError, json.JSONDecodeError):
                    logging.warning("Cache metadata corrupted, creating new metadata")
                    self.metadata = {}
            else:
                self.metadata = {}

            logging.info(f"Disk cache initialized: {self.cache_dir}")

        except Exception as e:
            logging.warning(f"Failed to initialize disk cache: {e}")
            self.cache_enabled = False

    def _get_cache_key(
        self, image_path: str, target_size: QSize, scale_factor: float = 1.0
    ) -> str:
        """
        Generate a unique cache key for an image with specific parameters.

        Args:
            image_path: Path to the source image
            target_size: Target size for the processed image
            scale_factor: Scale factor applied

        Returns:
            Unique cache key string
        """
        # Create a hash based on file path, size, scale factor, and file modification time
        try:
            mtime = os.path.getmtime(image_path)
            key_data = f"{image_path}_{target_size.width()}x{target_size.height()}_{scale_factor}_{mtime}"
            return hashlib.md5(key_data.encode()).hexdigest()
        except OSError:
            # If we can't get modification time, use current time (will miss cache)
            key_data = f"{image_path}_{target_size.width()}x{target_size.height()}_{scale_factor}_{time.time()}"
            return hashlib.md5(key_data.encode()).hexdigest()

    def _get_cache_file_path(self, cache_key: str) -> Path:
        """Get the file path for a cache key."""
        return self.cache_dir / f"{cache_key}.png"

    def get_cached_image(
        self, image_path: str, target_size: QSize, scale_factor: float = 1.0
    ) -> QPixmap | None:
        """
        Retrieve a cached image if available and valid.

        Args:
            image_path: Path to the source image
            target_size: Target size for the processed image
            scale_factor: Scale factor applied

        Returns:
            Cached QPixmap if available, None otherwise
        """
        if not self.cache_enabled:
            return None

        try:
            cache_key = self._get_cache_key(image_path, target_size, scale_factor)
            cache_file = self._get_cache_file_path(cache_key)

            # Check if cache file exists and is valid
            if cache_file.exists() and cache_key in self.metadata:
                # Verify source file hasn't changed
                try:
                    current_mtime = os.path.getmtime(image_path)
                    cached_mtime = self.metadata[cache_key].get("source_mtime", 0)

                    if current_mtime <= cached_mtime:
                        # Load cached image
                        pixmap = QPixmap(str(cache_file))
                        if not pixmap.isNull():
                            self.cache_hits += 1
                            logging.debug(
                                f"Disk cache hit: {os.path.basename(image_path)}"
                            )

                            # Update access time in metadata
                            self.metadata[cache_key]["last_access"] = time.time()
                            return pixmap
                    else:
                        # Source file has been modified, remove stale cache
                        self._remove_cache_entry(cache_key)

                except OSError:
                    # Can't check modification time, assume cache is stale
                    self._remove_cache_entry(cache_key)

            self.cache_misses += 1
            return None

        except Exception as e:
            logging.debug(f"Error retrieving cached image: {e}")
            return None

    def cache_image(
        self,
        image_path: str,
        pixmap: QPixmap,
        target_size: QSize,
        scale_factor: float = 1.0,
    ) -> bool:
        """
        Cache a processed image to disk.

        Args:
            image_path: Path to the source image
            pixmap: Processed QPixmap to cache
            target_size: Target size for the processed image
            scale_factor: Scale factor applied

        Returns:
            True if caching succeeded, False otherwise
        """
        if not self.cache_enabled or pixmap.isNull():
            return False

        try:
            cache_key = self._get_cache_key(image_path, target_size, scale_factor)
            cache_file = self._get_cache_file_path(cache_key)

            # Save the pixmap to cache
            if pixmap.save(str(cache_file), "PNG"):
                # Update metadata
                try:
                    source_mtime = os.path.getmtime(image_path)
                except OSError:
                    source_mtime = time.time()

                self.metadata[cache_key] = {
                    "source_path": image_path,
                    "source_mtime": source_mtime,
                    "cache_time": time.time(),
                    "last_access": time.time(),
                    "target_width": target_size.width(),
                    "target_height": target_size.height(),
                    "scale_factor": scale_factor,
                    "file_size": cache_file.stat().st_size,
                }

                self.cache_writes += 1
                logging.debug(f"Cached image: {os.path.basename(image_path)}")

                # Periodically save metadata and check cache size
                if self.cache_writes % 10 == 0:
                    self._save_metadata()
                    self._check_cache_size()

                return True

        except Exception as e:
            logging.debug(f"Error caching image: {e}")

        return False

    def _remove_cache_entry(self, cache_key: str) -> None:
        """Remove a cache entry and its file."""
        try:
            cache_file = self._get_cache_file_path(cache_key)
            if cache_file.exists():
                cache_file.unlink()

            if cache_key in self.metadata:
                del self.metadata[cache_key]

        except Exception as e:
            logging.debug(f"Error removing cache entry: {e}")

    def _save_metadata(self) -> None:
        """Save metadata to disk."""
        try:
            with open(self.metadata_file, "w") as f:
                json.dump(self.metadata, f, indent=2)
        except Exception as e:
            logging.warning(f"Failed to save cache metadata: {e}")

    def _check_cache_size(self) -> None:
        """Check cache size and cleanup if necessary."""
        try:
            total_size = sum(
                entry.get("file_size", 0) for entry in self.metadata.values()
            )
            max_size_bytes = self.max_cache_size_mb * 1024 * 1024

            if total_size > max_size_bytes:
                self._cleanup_cache()

        except Exception as e:
            logging.warning(f"Error checking cache size: {e}")

    def _cleanup_cache(self) -> None:
        """Clean up old cache entries to free space."""
        try:
            logging.info("Cleaning up disk cache...")

            # Sort entries by last access time (oldest first)
            sorted_entries = sorted(
                self.metadata.items(), key=lambda x: x[1].get("last_access", 0)
            )

            # Remove oldest 25% of entries
            entries_to_remove = len(sorted_entries) // 4
            for cache_key, _ in sorted_entries[:entries_to_remove]:
                self._remove_cache_entry(cache_key)

            self._save_metadata()
            self.cache_cleanups += 1

            logging.info(
                f"Cache cleanup completed: removed {entries_to_remove} entries"
            )

        except Exception as e:
            logging.warning(f"Error during cache cleanup: {e}")

    def get_cache_stats(self) -> dict[str, Any]:
        """Get cache statistics."""
        try:
            total_size = sum(
                entry.get("file_size", 0) for entry in self.metadata.values()
            )
            total_size_mb = total_size / (1024 * 1024)
        except:
            total_size_mb = 0

        hit_rate = 0
        if self.cache_hits + self.cache_misses > 0:
            hit_rate = (self.cache_hits / (self.cache_hits + self.cache_misses)) * 100

        return {
            "enabled": self.cache_enabled,
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "hit_rate_percent": round(hit_rate, 1),
            "cache_writes": self.cache_writes,
            "cache_cleanups": self.cache_cleanups,
            "total_entries": len(self.metadata),
            "total_size_mb": round(total_size_mb, 1),
            "cache_dir": str(self.cache_dir),
        }

    def clear_cache(self) -> None:
        """Clear all cache entries."""
        try:
            for cache_key in list(self.metadata.keys()):
                self._remove_cache_entry(cache_key)

            self.metadata.clear()
            self._save_metadata()

            logging.info("Disk cache cleared")

        except Exception as e:
            logging.warning(f"Error clearing cache: {e}")

    def shutdown(self) -> None:
        """Clean shutdown of cache manager."""
        try:
            self._save_metadata()
            logging.info("Disk cache manager shutdown completed")
        except Exception as e:
            logging.warning(f"Error during cache shutdown: {e}")
